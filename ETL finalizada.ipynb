{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "199eb769",
   "metadata": {},
   "outputs": [],
   "source": [
    "###PARA EXECUTAR AS CELULAS DO ZERO, DESCOMENTE ESSES COMANDOS E EXECUTE A CELULA PRIMEIRO\n",
    "import shutil\n",
    "\n",
    "#shutil.rmtree(\"ml\")\n",
    "#shutil.rmtree(\"data_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d347f8f2-c809-4684-9f8c-a61c09d5c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.2.0-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-33da8799-d4da-4ec4-ac14-08325bb50f54;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-core_2.12;1.1.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "downloading https://repo1.maven.org/maven2/io/delta/delta-core_2.12/1.1.0/delta-core_2.12-1.1.0.jar ...\n",
      "\t[SUCCESSFUL ] io.delta#delta-core_2.12;1.1.0!delta-core_2.12.jar (1511ms)\n",
      "downloading https://repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.8/antlr4-runtime-4.8.jar ...\n",
      "\t[SUCCESSFUL ] org.antlr#antlr4-runtime;4.8!antlr4-runtime.jar (253ms)\n",
      "downloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar ...\n",
      "\t[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.9.13!jackson-core-asl.jar (171ms)\n",
      ":: resolution report :: resolve 6154ms :: artifacts dl 1941ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-core_2.12;1.1.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   3   |   3   |   0   ||   3   |   3   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-33da8799-d4da-4ec4-ac14-08325bb50f54\n",
      "\tconfs: [default]\n",
      "\t3 artifacts copied, 0 already retrieved (2841kB/9ms)\n",
      "22/08/10 04:15:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from delta.tables import *\n",
    "from delta import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "import json\n",
    "import requests\n",
    "\n",
    "#Inicialização do ambiente Spark\n",
    "#Configuração necessária para utilização do Delta Lake\n",
    "builder = SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b97a83",
   "metadata": {},
   "source": [
    "Atividade 1: Ingestão e normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be7c6fd-d9d8-475f-b34f-dfe22ec13334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abertura dos dados iniciais referentes aos pedidos\n",
    "raw_path = \"pedidos.csv\"\n",
    "raw_df = spark.read\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"inferSchema\",\"true\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .load(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aaead90-2cbc-42b1-af74-83dbc51e5aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+--------------------+------------+-------------------+---------------+-----+\n",
      "| id|     nome|sobrenome|               email|valor_pedido|        data_pedido|        tipo_cc|id_ip|\n",
      "+---+---------+---------+--------------------+------------+-------------------+---------------+-----+\n",
      "|  1|Aleksandr| Crighton|acrighton0@instag...|      $71.31|2021-08-21 14:18:35|            jcb|    1|\n",
      "|  2|      Tad|   Arangy|tarangy1@studiopr...|      $28.12|2021-10-28 22:44:27|        maestro|    2|\n",
      "|  3|     Wake|   Samart|   wsamart2@ning.com|     $148.18|2022-06-26 22:33:37|  visa-electron|    3|\n",
      "|  4|    Svend|  Morfell|smorfell3@arizona...|     $148.74|2021-12-23 15:19:03|            jcb|    4|\n",
      "|  5|   Phoebe|Wealthall|pwealthall4@smugm...|     $146.84|2022-04-16 23:08:17|        maestro|    5|\n",
      "|  6|    Sayre|   Ashbey|sashbey5@google.c...|     $118.62|2022-06-14 22:24:33|            jcb|    6|\n",
      "|  7|      Dun|   Breens|dbreens6@seattlet...|     $136.92|2021-09-24 17:54:06|  visa-electron|    7|\n",
      "|  8|    Reine|   Noakes|rnoakes7@nbcnews.com|      $53.63|2022-04-01 04:13:58|       bankcard|    8|\n",
      "|  9|   Flossy|  Raynton|fraynton8@telegra...|     $144.20|2021-09-10 23:26:33|            jcb|    9|\n",
      "| 10|   Marjie|Errington|merrington9@unice...|      $87.56|2021-12-18 00:34:57|americanexpress|   10|\n",
      "+---+---------+---------+--------------------+------------+-------------------+---------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a495e3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Conversão dos dados para Parquet\n",
    "raw_df.select(\"*\").write.format(\"parquet\").save(\"data_parquet\")\n",
    "df = spark.read.parquet(\"data_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ee321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria os diretórios referentes as camadas do pipeline\n",
    "os.mkdir('ml')\n",
    "os.mkdir(\"ml/bronze\")\n",
    "os.mkdir(\"ml/silver\")\n",
    "os.mkdir(\"ml/gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f411448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, nome: string, sobrenome: string, email: string, valor_pedido: string, data_pedido: string, tipo_cc: string, id_ip: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path da Layer Bronze\n",
    "DELTALAKE_BRONZE_PATH = \"ml/bronze\"\n",
    "\n",
    "# Inicializa a tabela delta bronze com os dados inciais\n",
    "df.write.format('delta').mode('overwrite').save(DELTALAKE_BRONZE_PATH)\n",
    "\n",
    "# Registra a tabela SQL no banco de dados\n",
    "spark.sql(f\"CREATE TABLE bronze USING delta LOCATION '{DELTALAKE_BRONZE_PATH}'\") \n",
    "\n",
    "# Leitura da tabela\n",
    "request_stats = spark.read.format(\"delta\").load(DELTALAKE_BRONZE_PATH)\n",
    "\n",
    "display(request_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42a6c994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---------+--------------------+------------+-------------------+---------------+-----+\n",
      "| id|     nome|sobrenome|               email|valor_pedido|        data_pedido|        tipo_cc|id_ip|\n",
      "+---+---------+---------+--------------------+------------+-------------------+---------------+-----+\n",
      "|  1|Aleksandr| Crighton|acrighton0@instag...|      $71.31|2021-08-21 14:18:35|            jcb|    1|\n",
      "|  2|      Tad|   Arangy|tarangy1@studiopr...|      $28.12|2021-10-28 22:44:27|        maestro|    2|\n",
      "|  3|     Wake|   Samart|   wsamart2@ning.com|     $148.18|2022-06-26 22:33:37|  visa-electron|    3|\n",
      "|  4|    Svend|  Morfell|smorfell3@arizona...|     $148.74|2021-12-23 15:19:03|            jcb|    4|\n",
      "|  5|   Phoebe|Wealthall|pwealthall4@smugm...|     $146.84|2022-04-16 23:08:17|        maestro|    5|\n",
      "|  6|    Sayre|   Ashbey|sashbey5@google.c...|     $118.62|2022-06-14 22:24:33|            jcb|    6|\n",
      "|  7|      Dun|   Breens|dbreens6@seattlet...|     $136.92|2021-09-24 17:54:06|  visa-electron|    7|\n",
      "|  8|    Reine|   Noakes|rnoakes7@nbcnews.com|      $53.63|2022-04-01 04:13:58|       bankcard|    8|\n",
      "|  9|   Flossy|  Raynton|fraynton8@telegra...|     $144.20|2021-09-10 23:26:33|            jcb|    9|\n",
      "| 10|   Marjie|Errington|merrington9@unice...|      $87.56|2021-12-18 00:34:57|americanexpress|   10|\n",
      "+---+---------+---------+--------------------+------------+-------------------+---------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request_stats.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7794d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleção das colunas para concatenação e abertura de nova coluna com os dados concatenados\n",
    "concat_col_list = ['nome','sobrenome']\n",
    "request_stats = request_stats.withColumn('nome_completo',concat_ws('_',*concat_col_list))\n",
    "\n",
    "#Remoção das colunas concatenadas\n",
    "request_stats = request_stats.drop(\"nome\").drop(\"sobrenome\")\n",
    "\n",
    "#Reorganização da tabela \n",
    "request_stats.select(\"id\",\"nome_completo\",\"email\",\"valor_pedido\",\"data_pedido\",\"tipo_cc\",\"id_ip\")\n",
    "request_stats = request_stats.select(\"id\",\"nome_completo\",\"email\",\"valor_pedido\",\"data_pedido\",\"tipo_cc\",\"id_ip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "222b982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+--------------------+------------+-------------------+---------------+-----+\n",
      "| id|     nome_completo|               email|valor_pedido|        data_pedido|        tipo_cc|id_ip|\n",
      "+---+------------------+--------------------+------------+-------------------+---------------+-----+\n",
      "|  1|Aleksandr_Crighton|acrighton0@instag...|      $71.31|2021-08-21 14:18:35|            jcb|    1|\n",
      "|  2|        Tad_Arangy|tarangy1@studiopr...|      $28.12|2021-10-28 22:44:27|        maestro|    2|\n",
      "|  3|       Wake_Samart|   wsamart2@ning.com|     $148.18|2022-06-26 22:33:37|  visa-electron|    3|\n",
      "|  4|     Svend_Morfell|smorfell3@arizona...|     $148.74|2021-12-23 15:19:03|            jcb|    4|\n",
      "|  5|  Phoebe_Wealthall|pwealthall4@smugm...|     $146.84|2022-04-16 23:08:17|        maestro|    5|\n",
      "|  6|      Sayre_Ashbey|sashbey5@google.c...|     $118.62|2022-06-14 22:24:33|            jcb|    6|\n",
      "|  7|        Dun_Breens|dbreens6@seattlet...|     $136.92|2021-09-24 17:54:06|  visa-electron|    7|\n",
      "|  8|      Reine_Noakes|rnoakes7@nbcnews.com|      $53.63|2022-04-01 04:13:58|       bankcard|    8|\n",
      "|  9|    Flossy_Raynton|fraynton8@telegra...|     $144.20|2021-09-10 23:26:33|            jcb|    9|\n",
      "| 10|  Marjie_Errington|merrington9@unice...|      $87.56|2021-12-18 00:34:57|americanexpress|   10|\n",
      "+---+------------------+--------------------+------------+-------------------+---------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request_stats.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7a71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remoção do caractere \"$\" da coluna de valores do pedido e conversão para tipo double\n",
    "# Conversão do tipo da coluna de datas para timestamp\n",
    "request_stats = request_stats.withColumn('valor_pedido', regexp_replace('valor_pedido', '\\$','').cast('double'))\n",
    "request_stats = request_stats.withColumn('data_pedido', to_timestamp(\"data_pedido\", 'yyyy-MM-dd HH:mm:ss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bdba5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+--------------------+------------+-------------------+---------------+-----+\n",
      "| id|     nome_completo|               email|valor_pedido|        data_pedido|        tipo_cc|id_ip|\n",
      "+---+------------------+--------------------+------------+-------------------+---------------+-----+\n",
      "|  1|Aleksandr_Crighton|acrighton0@instag...|       71.31|2021-08-21 14:18:35|            jcb|    1|\n",
      "|  2|        Tad_Arangy|tarangy1@studiopr...|       28.12|2021-10-28 22:44:27|        maestro|    2|\n",
      "|  3|       Wake_Samart|   wsamart2@ning.com|      148.18|2022-06-26 22:33:37|  visa-electron|    3|\n",
      "|  4|     Svend_Morfell|smorfell3@arizona...|      148.74|2021-12-23 15:19:03|            jcb|    4|\n",
      "|  5|  Phoebe_Wealthall|pwealthall4@smugm...|      146.84|2022-04-16 23:08:17|        maestro|    5|\n",
      "|  6|      Sayre_Ashbey|sashbey5@google.c...|      118.62|2022-06-14 22:24:33|            jcb|    6|\n",
      "|  7|        Dun_Breens|dbreens6@seattlet...|      136.92|2021-09-24 17:54:06|  visa-electron|    7|\n",
      "|  8|      Reine_Noakes|rnoakes7@nbcnews.com|       53.63|2022-04-01 04:13:58|       bankcard|    8|\n",
      "|  9|    Flossy_Raynton|fraynton8@telegra...|       144.2|2021-09-10 23:26:33|            jcb|    9|\n",
      "| 10|  Marjie_Errington|merrington9@unice...|       87.56|2021-12-18 00:34:57|americanexpress|   10|\n",
      "+---+------------------+--------------------+------------+-------------------+---------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, nome_completo: string, email: string, valor_pedido: double, data_pedido: timestamp, tipo_cc: string, id_ip: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "request_stats.show(10)\n",
    "display(request_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95955b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, nome_completo: string, email: string, valor_pedido: double, data_pedido: timestamp, tipo_cc: string, id_ip: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path da layer Silver\n",
    "DELTALAKE_SILVER_PATH = \"ml/silver\"\n",
    "\n",
    "# Inicializa a tabela delta silver com os dados inciais\n",
    "request_stats.write.format('delta').mode('overwrite').save(DELTALAKE_SILVER_PATH)\n",
    "\n",
    "# Registra a tabela SQL no banco de dados\n",
    "spark.sql(\"CREATE TABLE if not exists silver USING DELTA LOCATION '\" + DELTALAKE_SILVER_PATH + \"'\")\n",
    "\n",
    "# Leitura da tabela\n",
    "request_stats = spark.read.format(\"delta\").load(DELTALAKE_SILVER_PATH)\n",
    "\n",
    "display(request_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c801367d",
   "metadata": {},
   "source": [
    "Atividade 2: Enriquecimento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c713f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+--------------------+\n",
      "| id|            ip|          user_agent|\n",
      "+---+--------------+--------------------+\n",
      "|  1|126.65.243.231|Mozilla/5.0 (Wind...|\n",
      "|  2| 181.81.197.29|Mozilla/5.0 (X11;...|\n",
      "|  3|  225.79.10.95|Mozilla/5.0 (Wind...|\n",
      "|  4| 138.177.78.33|Mozilla/5.0 (Maci...|\n",
      "|  5|   2.85.122.24|Mozilla/5.0 (Maci...|\n",
      "|  6| 188.90.71.147|Mozilla/5.0 (Wind...|\n",
      "|  7| 75.104.245.95|Mozilla/5.0 (Wind...|\n",
      "|  8|149.11.100.128|Mozilla/5.0 (Wind...|\n",
      "|  9|201.138.216.30|Mozilla/5.0 (Wind...|\n",
      "| 10| 206.28.109.87|Mozilla/5.0 (Wind...|\n",
      "+---+--------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Abertura dos dados iniciais referentes aos ips\n",
    "ip_path = \"ips.csv\"\n",
    "ip_df = spark.read\\\n",
    "                .format(\"csv\")\\\n",
    "                .option(\"inferSchema\",\"true\")\\\n",
    "                .option(\"header\",\"true\")\\\n",
    "                .load(ip_path)\n",
    "ip_df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "591e0f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ip: string (nullable = true)\n",
      " |-- regiao: string (nullable = true)\n",
      " |-- cidade: string (nullable = true)\n",
      " |-- pais: string (nullable = true)\n",
      "\n",
      "+---------------+--------------------+-------------+-------------+\n",
      "|ip             |regiao              |cidade       |pais         |\n",
      "+---------------+--------------------+-------------+-------------+\n",
      "|126.65.243.231 |Saitama Prefecture  |Yashio       |Japan        |\n",
      "|181.81.197.29  |Santa Fe            |Rosario      |Argentina    |\n",
      "|225.79.10.95   |                    |             |             |\n",
      "|138.177.78.33  |Pennsylvania        |Whitehall    |United States|\n",
      "|2.85.122.24    |Macedonia and Thrace|Kondariotissa|Greece       |\n",
      "|188.90.71.147  |Gelderland          |Brakel       |Netherlands  |\n",
      "|75.104.245.95  |New York            |New York     |United States|\n",
      "|149.11.100.128 |Overijssel          |Oldenzaal    |Netherlands  |\n",
      "|201.138.216.30 |Mexico City         |Mexico City  |Mexico       |\n",
      "|206.28.109.87  |New York            |New York     |United States|\n",
      "|102.206.87.165 |Port Louis          |Port Louis   |Mauritius    |\n",
      "|3.205.136.8    |Illinois            |Chicago      |United States|\n",
      "|21.144.193.174 |Pennsylvania        |Whitehall    |United States|\n",
      "|182.234.67.150 |Taoyuan City        |Taoyuan City |Taiwan       |\n",
      "|111.163.192.214|Tianjin             |Tianjin      |China        |\n",
      "|162.152.2.252  |Texas               |Dallas       |United States|\n",
      "|218.131.103.221|Tokyo               |Minato       |Japan        |\n",
      "|245.150.194.22 |                    |             |             |\n",
      "|246.19.60.43   |                    |             |             |\n",
      "|32.69.36.180   |New York            |New York     |United States|\n",
      "+---------------+--------------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Função com base na API IPWHOIS para obtenção dos dados para enriquecimento da tabela\n",
    "def ipwhois(ip):\n",
    "    url = requests.get(f'https://ipwhois.app/json/{ip}')\n",
    "    json = url.json()\n",
    "    sucesso = json['success']\n",
    "    ip = ip\n",
    "    if sucesso == True:\n",
    "        regiao = json['region']\n",
    "        cidade = json['city']\n",
    "        pais = json['country']\n",
    "    else:\n",
    "        regiao = \"\"\n",
    "        cidade = \"\"\n",
    "        pais = \"\"\n",
    "    return ip, regiao, cidade, pais\n",
    "\n",
    "#Iteração da coluna de ips\n",
    "data_collect = ip_df.select(\"ip\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#Inicialização de novo dataframe com dados provenientes da API IPWHOIS\n",
    "rdd = [ipwhois(x) for x in data_collect]\n",
    "newColumns = [\"ip\", \"regiao\",\"cidade\",\"pais\"]\n",
    "new_ip_df = spark.createDataFrame(data=rdd, schema = newColumns)\n",
    "new_ip_df.printSchema()\n",
    "new_ip_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab6f376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join dos dataframes referentes a ip\n",
    "IP_df = ip_df.join(new_ip_df, on=['ip'], how='inner').drop('ip')\n",
    "\n",
    "#Novo parquet na Layer Silver referente a tabela de ips enriquecida\n",
    "IP_df.select(\"*\").write.format(\"parquet\").save(\"ml/silver/ip_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acdcd799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+-------------+-------------+\n",
      "| id|          user_agent|              regiao|       cidade|         pais|\n",
      "+---+--------------------+--------------------+-------------+-------------+\n",
      "|  1|Mozilla/5.0 (Wind...|  Saitama Prefecture|       Yashio|        Japan|\n",
      "|  2|Mozilla/5.0 (X11;...|            Santa Fe|      Rosario|    Argentina|\n",
      "|  3|Mozilla/5.0 (Wind...|                    |             |             |\n",
      "|  4|Mozilla/5.0 (Maci...|        Pennsylvania|    Whitehall|United States|\n",
      "|  5|Mozilla/5.0 (Maci...|Macedonia and Thrace|Kondariotissa|       Greece|\n",
      "|  6|Mozilla/5.0 (Wind...|          Gelderland|       Brakel|  Netherlands|\n",
      "|  7|Mozilla/5.0 (Wind...|            New York|     New York|United States|\n",
      "|  8|Mozilla/5.0 (Wind...|          Overijssel|    Oldenzaal|  Netherlands|\n",
      "|  9|Mozilla/5.0 (Wind...|         Mexico City|  Mexico City|       Mexico|\n",
      "| 10|Mozilla/5.0 (Wind...|            New York|     New York|United States|\n",
      "+---+--------------------+--------------------+-------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IP_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d54fc",
   "metadata": {},
   "source": [
    "Atividade 3: Transformação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3efe02e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, nome_completo: string, email: string, valor_pedido: double, data_pedido: timestamp, tipo_cc: string, regiao: string, cidade: string, pais: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Agregação de dados das duas tabelas (pedidos e ips) e remoção das colunas de pouca relevância\n",
    "aggregated_df = request_stats.join(IP_df.withColumnRenamed(\"id\", \"id_ip\"), on=['id_ip'], how='inner').drop(\"id_ip\").drop(\"user_agent\")\n",
    "\n",
    "# Path da layer Gold\n",
    "DELTALAKE_GOLD_PATH = \"ml/gold\"\n",
    "\n",
    "# Inicializa a tabela parquet gold com os dados inciais\n",
    "aggregated_df.write.format('delta').save(DELTALAKE_GOLD_PATH)\n",
    "\n",
    "# Registra a tabela SQL no banco de dados\n",
    "spark.sql(f\"CREATE TABLE if not exists gold USING delta LOCATION '{DELTALAKE_GOLD_PATH}'\")\n",
    "\n",
    "display(aggregated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceee6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df.show(10, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c77da00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "030483b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"ml/gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65ded2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "67f1dc6f6f712f7142079021955b91e049abb319dcfdc9eed010dd73dd4d845d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
